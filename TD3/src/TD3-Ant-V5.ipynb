{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run the below cell to download the MuJoCo dependencies"
      ],
      "metadata": {
        "id": "kQdCbE0A2UIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gymnasium[mujoco] mujoco"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NSQT9cmkLW_a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40ca72e-5061-4406-9e86-b04ad473e0cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mujoco\n",
            "  Downloading mujoco-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Requirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.37.2)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (26.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.13.0)\n",
            "Collecting glfw (from mujoco)\n",
            "  Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.py39.py310.py311.py312.py313.py314-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco) (3.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (11.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (3.23.0)\n",
            "Downloading mujoco-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.py39.py310.py311.py312.py313.py314-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.10.0 mujoco-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lPpgmu6bbnCV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTING LIBRARIES**"
      ],
      "metadata": {
        "id": "datKnudtXc1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "592W2ND6Vrki"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import deque\n",
        "import wandb\n",
        "\n",
        "import gymnasium as gym\n",
        "# from gymnasium.vector import SyncVectorEnv\n",
        "from gymnasium.wrappers import RecordVideo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MUJOCO_GL\"] = \"egl\""
      ],
      "metadata": {
        "id": "C_JNsAjzZ5T-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_environment(cfgs, eval = False):\n",
        "\n",
        "#   def _init():\n",
        "#       env = gym.make( id=cfgs.id , render_mode=\"rgb_array\", max_episode_steps=cfg.max_steps)\n",
        "#       return env\n",
        "\n",
        "#   return _init"
      ],
      "metadata": {
        "id": "60iIOcw1J2vD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_environment(cfgs, eval = False):\n",
        "  env = gym.make( id=cfgs.id , render_mode=\"rgb_array\", max_episode_steps=cfg.max_steps)\n",
        "  return env"
      ],
      "metadata": {
        "id": "r7ghF0Mvsxjh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **WANDB RUN**"
      ],
      "metadata": {
        "id": "HWGd2YkB2l8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_runs(cfg):\n",
        "\n",
        "  wandb.login(key = \"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\")\n",
        "  run = wandb.init(\n",
        "    entity=\"ajheshbasnet-kpriet\",\n",
        "    project=\"ddpg\",\n",
        "    name = \"DDPG\",\n",
        "    config=vars(cfg),\n",
        "  )\n",
        "\n",
        "  return run"
      ],
      "metadata": {
        "id": "bS0X6VK-W6C3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONFIGURATIONS**"
      ],
      "metadata": {
        "id": "58FAgHd6XgNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class configuration:\n",
        "  id = \"Ant-v5\"\n",
        "  n_rollouts = 100_000\n",
        "  max_steps = 1000\n",
        "  eval_steps = 10_000\n",
        "  global_steps = 0\n",
        "  buffer_size = 800_000\n",
        "  eval_loops = 3\n",
        "  batch_size = 512\n",
        "  wandb_log_steps = 50\n",
        "  start_training = 50_000\n",
        "  training_step = 2\n",
        "  actor_freq = 3\n",
        "  critic_lr = 2.5e-4\n",
        "  actor_lr = 2.5e-4\n",
        "  record_video = 500_000\n",
        "  eval_max_steps = 800\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "cfg = configuration()"
      ],
      "metadata": {
        "id": "vSCqFzICXY4j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SyncVectorEnv so that we can run the n-environments parrallelly and utilize the GPUs because single environment is wayy poor**"
      ],
      "metadata": {
        "id": "be7coiwP20R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# envs = SyncVectorEnv([create_environment(cfg) for _ in range(cfg.n_envs)])\n",
        "\n",
        "envs = create_environment(cfg)"
      ],
      "metadata": {
        "id": "QpR1buugKk6H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking environment is working or not:)**"
      ],
      "metadata": {
        "id": "REzQ_aBy2u5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actor and Critic Netowrk**"
      ],
      "metadata": {
        "id": "Fy_OPT6e3O1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, action_dim):\n",
        "    super().__init__()\n",
        "    self.sequential = nn.Sequential(\n",
        "        nn.Linear(input_dim, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, action_dim),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.sequential(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "vh8HBQTyOTA1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.sequential = nn.Sequential(\n",
        "        nn.Linear(input_dim, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, state, action):\n",
        "    x = torch.cat([state, action], dim = 1)\n",
        "    x = self.sequential(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "oPaVL6a9O950"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(envs.observation_space,\"\\t\", envs.action_space,)"
      ],
      "metadata": {
        "id": "or3uYM8APYcY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d4a4dc-05e7-419f-9c34-478a3aed27a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(-inf, inf, (105,), float64) \t Box(-1.0, 1.0, (8,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actornet = Actor(envs.observation_space.shape[0], envs.action_space.shape[0]).to(cfg.device)  #type: ignore\n",
        "criticnet1 = Critic(envs.observation_space.shape[0]+envs.action_space.shape[0]).to(cfg.device)  #type: ignore\n",
        "criticnet2 = Critic(envs.observation_space.shape[0]+envs.action_space.shape[0]).to(cfg.device)  #type: ignore\n",
        "\n",
        "TargetActor = Actor(envs.observation_space.shape[0], envs.action_space.shape[0]).to(cfg.device) #type: ignore\n",
        "TargetCritic1 = Critic(envs.observation_space.shape[0]+envs.action_space.shape[0]).to(cfg.device) #type: ignore\n",
        "TargetCritic2 = Critic(envs.observation_space.shape[0]+envs.action_space.shape[0]).to(cfg.device) #type: ignore\n",
        "\n",
        "TargetActor.load_state_dict(actornet.state_dict())\n",
        "TargetCritic1.load_state_dict(criticnet1.state_dict())\n",
        "TargetCritic2.load_state_dict(criticnet2.state_dict())"
      ],
      "metadata": {
        "id": "xbTU-sNyPUeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c392064b-e913-4a6d-f075-00c9ec754fc1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'''Parameters:\n",
        "=================================================================\n",
        "actor-network     : {sum(p.numel() for p in actornet.parameters())/1e3} k\n",
        "critic-network(s) : {sum(p.numel() for p in criticnet1.parameters())/ 1e3} k + {sum(p.numel() for p in criticnet2.parameters())/ 1e3} k\n",
        "=================================================================\n",
        "      ''')"
      ],
      "metadata": {
        "id": "Mji3FfE4P1HP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f40fc6d6-abee-4d6d-ff59-a99a5a8643a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:\n",
            "=================================================================\n",
            "actor-network     : 187.656 k\n",
            "critic-network(s) : 189.953 k + 189.953 k\n",
            "=================================================================\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Loop**"
      ],
      "metadata": {
        "id": "_MWMoXRF3Tqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(actornet, record_video = False):\n",
        "\n",
        "  eval_env = gym.make(id = cfg.id, render_mode = 'rgb_array' ,max_episode_steps=cfg.eval_max_steps)\n",
        "  if record_video:\n",
        "    video_dir = f\"videos/{int(time.time())}\"\n",
        "    eval_env = RecordVideo(eval_env,  video_folder=video_dir, episode_trigger=lambda ep: True)\n",
        "\n",
        "  net_reward = 0\n",
        "  net_step = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for _ in range(cfg.eval_loops):\n",
        "\n",
        "      done = False\n",
        "\n",
        "      episodic_reward = 0\n",
        "      episodic_step = 0\n",
        "      state = eval_env.reset()[0]\n",
        "\n",
        "      while not done:\n",
        "\n",
        "        stateT = torch.tensor(state, dtype=torch.float32, device=cfg.device)\n",
        "        action = np.array(actornet(stateT).cpu().numpy())\n",
        "        nxt_state, reward, terminated, truncated, _ = eval_env.step(action)\n",
        "        done = terminated or truncated\n",
        "        state = nxt_state\n",
        "\n",
        "        episodic_reward += float(reward)\n",
        "        episodic_step += 1\n",
        "\n",
        "      net_reward += episodic_reward\n",
        "      net_step  += episodic_step\n",
        "\n",
        "  net_reward = net_reward / cfg.eval_loops\n",
        "  net_step = net_step / cfg.eval_loops\n",
        "\n",
        "  eval_env.close()\n",
        "\n",
        "  return net_reward, net_step"
      ],
      "metadata": {
        "id": "m7xFx7s0WpLC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(actornet, False)"
      ],
      "metadata": {
        "id": "z2hkd4Aw6SL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76b74a98-de26-40ab-8f28-4cae8648b1c0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(793.4922706923782, 800.0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To sample the batches**"
      ],
      "metadata": {
        "id": "Xs-HECi93Wby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(memory, batch_size):\n",
        "    batches = random.sample(memory, batch_size)\n",
        "    state, action, reward, next_state, done = zip(*batches)\n",
        "\n",
        "    state = torch.stack(state).float().to(cfg.device)\n",
        "    action = torch.stack(action).float().to(cfg.device)\n",
        "    reward = torch.stack(reward).float().to(cfg.device)\n",
        "    next_state = torch.stack(next_state).float().to(cfg.device)\n",
        "    done = torch.stack(done).float().to(cfg.device)  # float for TD computation\n",
        "\n",
        "    return state, action, reward.view(-1, 1), next_state, done.view(-1, 1)"
      ],
      "metadata": {
        "id": "NC2tSGnliXeV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **REPLAY MEMORY**"
      ],
      "metadata": {
        "id": "pKROh-L3Z4_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = deque(maxlen = cfg.buffer_size)\n",
        "action_sigma = 0.1\n",
        "tau = 0.001\n",
        "gamma = 0.99\n",
        "noise_clip = 0.5\n",
        "policy_noise = 0.2\n",
        "global_step = cfg.global_steps"
      ],
      "metadata": {
        "id": "h-lQZ4unSgB2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critic_optimizer1 = torch.optim.AdamW(criticnet1.parameters(), lr = cfg.critic_lr)\n",
        "critic_optimizer2 = torch.optim.AdamW(criticnet2.parameters(), lr = cfg.critic_lr)\n",
        "actor_optimizer = torch.optim.AdamW(actornet.parameters(), lr = cfg.actor_lr)"
      ],
      "metadata": {
        "id": "YJwbt4RpR9kH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**W&B RUNS TO LOG THE METRICS**"
      ],
      "metadata": {
        "id": "r-aIg5JqZ9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = wandb_runs(cfg)"
      ],
      "metadata": {
        "id": "bY4z2rMkXM4v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "10848cf2-d1c0-42ec-83a2-8b9a116d894b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33majheshbasnet\u001b[0m (\u001b[33majheshbasnet-kpriet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260211_170659-50ms14so</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg/runs/50ms14so' target=\"_blank\">DDPG</a></strong> to <a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg' target=\"_blank\">https://wandb.ai/ajheshbasnet-kpriet/ddpg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg/runs/50ms14so' target=\"_blank\">https://wandb.ai/ajheshbasnet-kpriet/ddpg/runs/50ms14so</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Heart & Core of the notebook: DDPG Algorithm's Training Loop**"
      ],
      "metadata": {
        "id": "CU_YjGWi3biG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for _ in tqdm(range(cfg.n_rollouts)):\n",
        "\n",
        "  states = envs.reset()[0]\n",
        "\n",
        "  statesT= torch.tensor(states, dtype=torch.float32, device = cfg.device)\n",
        "\n",
        "  training_rewards = 0\n",
        "\n",
        "  for _ in range(cfg.max_steps):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      action = actornet(statesT).view(-1)\n",
        "\n",
        "    action_noise = torch.clamp(torch.randn_like(action), -noise_clip, noise_clip)\n",
        "\n",
        "    action = (action + action_sigma * action_noise)\n",
        "\n",
        "    action = torch.clamp(action, -1.0, 1.0).cpu().numpy()\n",
        "\n",
        "    next_states, rewards, terminated, truncated, _ =  envs.step(action)\n",
        "\n",
        "    done = terminated | truncated\n",
        "\n",
        "    next_statesT = torch.tensor(next_states, dtype=torch.float32, device = cfg.device)\n",
        "\n",
        "    actionT = torch.tensor(action, dtype=torch.float32, device = cfg.device)\n",
        "\n",
        "    rewardsT = torch.tensor(rewards, dtype=torch.float32, device=cfg.device)\n",
        "\n",
        "    training_rewards += float(rewards)\n",
        "\n",
        "    doneT = torch.tensor(done, dtype=torch.bool, device = cfg.device)\n",
        "\n",
        "    replay_buffer.append((statesT, actionT, rewardsT, next_statesT, doneT))\n",
        "\n",
        "    statesT = next_statesT\n",
        "\n",
        "    cfg.global_steps += 1\n",
        "\n",
        "    if cfg.global_steps% cfg.training_step == 0 and len(replay_buffer)>cfg.start_training:\n",
        "      # Sample batch\n",
        "      states_b, action_b, reward_b, next_states_b, dones_b = get_batches(replay_buffer, cfg.batch_size)\n",
        "\n",
        "      # Target Q\n",
        "      with torch.no_grad():\n",
        "\n",
        "        next_action_ = TargetActor(next_states_b)\n",
        "        noise_next_action = torch.clamp(torch.randn_like(next_action_) * policy_noise, -noise_clip, +noise_clip)\n",
        "        next_action = next_action_ + noise_next_action\n",
        "        next_action = torch.clamp(next_action, -1.0, 1.0)\n",
        "\n",
        "        target_next_q1 = TargetCritic1(next_states_b, next_action)\n",
        "        target_next_q2 = TargetCritic2(next_states_b, next_action)\n",
        "        target_q = reward_b + gamma * torch.min(target_next_q1, target_next_q2) * (1 - dones_b.float())\n",
        "\n",
        "      # Current critic Q\n",
        "      current_q1 = criticnet1(states_b, action_b)\n",
        "      current_q2 = criticnet2(states_b, action_b)\n",
        "\n",
        "      # Critic loss\n",
        "      critic_loss1 = torch.nn.functional.mse_loss(current_q1, target_q)\n",
        "      critic_loss2 = torch.nn.functional.mse_loss(current_q2, target_q)\n",
        "\n",
        "      # Optimize critic1\n",
        "      critic_optimizer1.zero_grad()\n",
        "      critic_loss1.backward()\n",
        "      critic_grad_norm1 = torch.nn.utils.clip_grad_norm_(criticnet1.parameters(), max_norm=1.0)\n",
        "      critic_optimizer1.step()\n",
        "\n",
        "      # Optimize critic2\n",
        "      critic_optimizer2.zero_grad()\n",
        "      critic_loss2.backward()\n",
        "      critic_grad_norm2 = torch.nn.utils.clip_grad_norm_(criticnet2.parameters(), max_norm=1.0)\n",
        "      critic_optimizer2.step()\n",
        "\n",
        "      # Actor loss (use current actor)\n",
        "      # Clone states_b to create an independent computational graph for actor update\n",
        "      states_b_actor = states_b.clone()\n",
        "      actor_actions = actornet(states_b_actor) # Renamed to avoid shadowing action_b from get_batches\n",
        "\n",
        "      min_q = torch.min(criticnet1(states_b_actor, actor_actions), criticnet2(states_b_actor, actor_actions))\n",
        "      actor_loss = -min_q.mean()\n",
        "\n",
        "      if cfg.global_steps%cfg.actor_freq==0:\n",
        "        for p in criticnet1.parameters():\n",
        "          p.requires_grad = False\n",
        "\n",
        "        for p in criticnet2.parameters():\n",
        "          p.requires_grad = False\n",
        "\n",
        "        # Optimize actor\n",
        "        actor_optimizer.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        actor_grad_norm = torch.nn.utils.clip_grad_norm_(actornet.parameters(), max_norm=1.0)\n",
        "        actor_optimizer.step()\n",
        "\n",
        "        for p in criticnet1.parameters():\n",
        "          p.requires_grad = True\n",
        "        for p in criticnet2.parameters():\n",
        "          p.requires_grad = True\n",
        "\n",
        "      advantages = (target_q - torch.min(current_q1, current_q2)).detach().mean()\n",
        "\n",
        "      runs.log(\n",
        "          {\n",
        "              \"actor-loss\": actor_loss.item(),\n",
        "              \"critic-loss1\": critic_loss1.item(),\n",
        "              \"critic-loss2\": critic_loss2.item(),\n",
        "              \"advantages\": advantages.item()\n",
        "          }\n",
        "      )\n",
        "      # Soft update targets\n",
        "      for target_param, param in zip(TargetCritic1.parameters(), criticnet1.parameters()):\n",
        "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "      for target_param, param in zip(TargetCritic2.parameters(), criticnet2.parameters()):\n",
        "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "      for target_param, param in zip(TargetActor.parameters(), actornet.parameters()):\n",
        "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "      runs.log({\"training-reward\": training_rewards, \"global-steps\": cfg.global_steps, \"memory\": len(replay_buffer)})\n",
        "\n",
        "      if cfg.global_steps%cfg.eval_steps==0 and cfg.global_steps>1:\n",
        "          rec = True if global_step%cfg.record_video==0 else False\n",
        "          eval_reward, eval_steps = evaluation(actornet, rec)\n",
        "          runs.log(\n",
        "              {\n",
        "                  \"eval-reward\": eval_reward,\n",
        "              }\n",
        "          )\n",
        "\n",
        "envs.close()\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "AnYrCFL0XspN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "be543f93-0ae9-4850-9ace-bcc6c7276582"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 65/100000 [03:14<82:58:49,  2.99s/it] \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-477758841.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0mactor_actions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactornet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_b_actor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Renamed to avoid shadowing action_b from get_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m       \u001b[0mmin_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriticnet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_b_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriticnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates_b_actor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m       \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mmin_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-826857911.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \"\"\"\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mRuns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_action_, noise_next_action"
      ],
      "metadata": {
        "id": "iXf7irLq09Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.clamp(torch.randn_like(next_action_), -noise_clip, noise_clip)"
      ],
      "metadata": {
        "id": "aBVav4LH8CMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the below cell to save the video from the latest Actor Network**"
      ],
      "metadata": {
        "id": "BL52dUql3pwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(actornet, True)"
      ],
      "metadata": {
        "id": "2aDI241Wi0nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **                         **END****"
      ],
      "metadata": {
        "id": "czl6Q_OzaZsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.global_steps"
      ],
      "metadata": {
        "id": "53fXpTWeacMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Qd-TToinFNj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}