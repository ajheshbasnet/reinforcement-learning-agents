{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Run the below cell to download the MuJoCo dependencies"
      ],
      "metadata": {
        "id": "kQdCbE0A2UIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gymnasium[mujoco] mujoco"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSQT9cmkLW_a",
        "outputId": "1e36c3db-fa89-4f34-8be3-7d7c5301247e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mujoco\n",
            "  Downloading mujoco-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m41.0/42.0 kB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m725.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gymnasium[mujoco] in /usr/local/lib/python3.12/dist-packages (1.2.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (0.0.4)\n",
            "Requirement already satisfied: imageio>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (2.37.2)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium[mujoco]) (26.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.4.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.12/dist-packages (from mujoco) (1.13.0)\n",
            "Collecting glfw (from mujoco)\n",
            "  Downloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.py39.py310.py311.py312.py313.py314-none-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: pyopengl in /usr/local/lib/python3.12/dist-packages (from mujoco) (3.1.10)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio>=2.14.1->gymnasium[mujoco]) (11.3.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (2025.3.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (6.5.2)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.12/dist-packages (from etils[epath]->mujoco) (3.23.0)\n",
            "Downloading mujoco-3.4.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading glfw-2.10.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38.py39.py310.py311.py312.py313.py314-none-manylinux_2_28_x86_64.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.5/243.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: glfw, mujoco\n",
            "Successfully installed glfw-2.10.0 mujoco-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lPpgmu6bbnCV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IMPORTING LIBRARIES**"
      ],
      "metadata": {
        "id": "datKnudtXc1D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "592W2ND6Vrki"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import deque\n",
        "import wandb\n",
        "\n",
        "import gymnasium as gym\n",
        "from gymnasium.vector import SyncVectorEnv\n",
        "from gymnasium.wrappers import RecordVideo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"MUJOCO_GL\"] = \"egl\""
      ],
      "metadata": {
        "id": "C_JNsAjzZ5T-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_environment(cfgs, eval = False):\n",
        "\n",
        "  def _init():\n",
        "      env = gym.make( id=cfgs.id , render_mode=\"rgb_array\", max_episode_steps=cfg.max_steps)\n",
        "      return env\n",
        "\n",
        "  return _init"
      ],
      "metadata": {
        "id": "60iIOcw1J2vD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **WANDB RUN**"
      ],
      "metadata": {
        "id": "HWGd2YkB2l8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wandb_runs(cfg):\n",
        "\n",
        "  wandb.login(key = \"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\")\n",
        "  run = wandb.init(\n",
        "    entity=\"ajheshbasnet-kpriet\",\n",
        "    project=\"ddpg\",\n",
        "    name = \"DDPG\",\n",
        "    config=vars(cfg),\n",
        "  )\n",
        "\n",
        "  return run"
      ],
      "metadata": {
        "id": "bS0X6VK-W6C3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CONFIGURATIONS**"
      ],
      "metadata": {
        "id": "58FAgHd6XgNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class configuration:\n",
        "  id = \"HalfCheetah-v5\"\n",
        "  n_envs = 8\n",
        "  n_rollouts = 100_000\n",
        "  max_steps = 1000\n",
        "  eval_steps = 10_000\n",
        "  global_steps = 0\n",
        "  buffer_size = 500_000\n",
        "  eval_loops = 3\n",
        "  batch_size = 128\n",
        "  trainng_step = 1\n",
        "  critic_lr = 2.5e-4\n",
        "  actor_lr = 2.5e-4\n",
        "  record_video = 500_000\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "cfg = configuration()"
      ],
      "metadata": {
        "id": "vSCqFzICXY4j"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SyncVectorEnv so that we can run the n-environments parrallelly and utilize the GPUs because single environment is wayy poor**"
      ],
      "metadata": {
        "id": "be7coiwP20R-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "envs = SyncVectorEnv([create_environment(cfg) for _ in range(cfg.n_envs)])"
      ],
      "metadata": {
        "id": "QpR1buugKk6H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking environment is working or not:)**"
      ],
      "metadata": {
        "id": "REzQ_aBy2u5d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "envs.reset()[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v30O_N7sKzeW",
        "outputId": "ad432434-9bca-4222-8723-d968b1c5ef19"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.06587524,  0.07457796, -0.09485435, -0.04748046,  0.05739668,\n",
              "       -0.06521819, -0.08906876,  0.05440453, -0.2159224 , -0.1004027 ,\n",
              "       -0.03345621, -0.04662377,  0.22998296,  0.03340072,  0.0473454 ,\n",
              "       -0.05126143,  0.18059978])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actor and Critic Netowrk**"
      ],
      "metadata": {
        "id": "Fy_OPT6e3O1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim, action_dim):\n",
        "    super().__init__()\n",
        "    self.sequential = nn.Sequential(\n",
        "        nn.Linear(input_dim, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, action_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.sequential(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "vh8HBQTyOTA1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Critic(nn.Module):\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.sequential = nn.Sequential(\n",
        "        nn.Linear(input_dim, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1)\n",
        "    )\n",
        "\n",
        "  def forward(self, state, action):\n",
        "    x = torch.cat([state, action], dim = 1)\n",
        "    x = self.sequential(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "oPaVL6a9O950"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(envs.single_observation_space,\"\\t\", envs.single_action_space,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or3uYM8APYcY",
        "outputId": "cd947af0-4077-4b37-e7db-40d75b2d342a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(-inf, inf, (17,), float64) \t Box(-1.0, 1.0, (6,), float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actornet = Actor(17, 6).to(cfg.device)\n",
        "criticnet = Critic(23).to(cfg.device)\n",
        "\n",
        "TargetActor = Actor(17, 6).to(cfg.device)\n",
        "TargetCritic = Critic(23).to(cfg.device)\n",
        "\n",
        "TargetActor.load_state_dict(actornet.state_dict())\n",
        "TargetCritic.load_state_dict(criticnet.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbTU-sNyPUeO",
        "outputId": "a1a052ae-6113-4d87-c676-62e5f5f68158"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'''Parameters:\n",
        "===========================\n",
        "actor-network :  {sum(p.numel() for p in actornet.parameters())/1e3} k\n",
        "critic-network : {sum(p.numel() for p in criticnet.parameters())/ 1e3} k\n",
        "===========================\n",
        "      ''')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mji3FfE4P1HP",
        "outputId": "a85edd1b-47ae-481d-fbad-14a3a8ba471e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters:\n",
            "===========================\n",
            "actor-network :  465.286 k\n",
            "critic-network : 466.177 k\n",
            "===========================\n",
            "      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Loop**"
      ],
      "metadata": {
        "id": "_MWMoXRF3Tqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(actornet, record_video = False):\n",
        "\n",
        "  eval_env = gym.make(id = cfg.id, render_mode = 'rgb_array' ,max_episode_steps=cfg.max_steps)\n",
        "  if record_video:\n",
        "    video_dir = f\"videos/{int(time.time())}\"\n",
        "    eval_env = RecordVideo(eval_env,  video_folder=video_dir, episode_trigger=lambda ep: True)\n",
        "\n",
        "  net_reward = 0\n",
        "  net_step = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "\n",
        "    for _ in range(cfg.eval_loops):\n",
        "\n",
        "      done = False\n",
        "\n",
        "      episodic_reward = 0\n",
        "      episodic_step = 0\n",
        "      state = eval_env.reset()[0]\n",
        "\n",
        "      while not done:\n",
        "\n",
        "        stateT = torch.tensor(state, dtype=torch.float32, device=cfg.device)\n",
        "        action = np.array(actornet(stateT).cpu())\n",
        "        nxt_state, reward, terminated, truncated, _ = eval_env.step(action)\n",
        "        done = terminated or truncated\n",
        "        state = nxt_state\n",
        "\n",
        "        episodic_reward += float(reward)\n",
        "        episodic_step += 1\n",
        "\n",
        "      net_reward += episodic_reward\n",
        "      net_step  += episodic_step\n",
        "\n",
        "  net_reward = net_reward / cfg.eval_loops\n",
        "  net_step = net_step / cfg.eval_loops\n",
        "\n",
        "  eval_env.close()\n",
        "\n",
        "  return net_reward, net_step"
      ],
      "metadata": {
        "id": "m7xFx7s0WpLC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**To sample the batches**"
      ],
      "metadata": {
        "id": "Xs-HECi93Wby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batches(memory, batch_size):\n",
        "    batches = random.sample(memory, batch_size)\n",
        "    state, action, reward, next_state, done = zip(*batches)\n",
        "\n",
        "    state = torch.stack(state).float().to(cfg.device)\n",
        "    action = torch.stack(action).float().to(cfg.device)\n",
        "    reward = torch.stack(reward).float().to(cfg.device)\n",
        "    next_state = torch.stack(next_state).float().to(cfg.device)\n",
        "    done = torch.stack(done).float().to(cfg.device)  # float for TD computation\n",
        "\n",
        "    state = state.reshape(-1, state.size(-1))\n",
        "    action = action.reshape(-1, action.size(-1))\n",
        "    reward = reward.reshape(-1,1)\n",
        "    next_state = next_state.reshape(-1, next_state.size(-1))\n",
        "    done = done.reshape(-1,1)\n",
        "\n",
        "    return state, action, reward, next_state, done\n"
      ],
      "metadata": {
        "id": "NC2tSGnliXeV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replay_buffer = deque(maxlen = cfg.buffer_size)\n",
        "action_sigma = 0.02\n",
        "tau = 0.005\n",
        "gamma = 0.98\n",
        "global_step = cfg.global_steps"
      ],
      "metadata": {
        "id": "h-lQZ4unSgB2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "critic_optimizer = torch.optim.AdamW(criticnet.parameters(), lr = cfg.critic_lr)\n",
        "actor_optimizer = torch.optim.AdamW(actornet.parameters(), lr = cfg.actor_lr)"
      ],
      "metadata": {
        "id": "YJwbt4RpR9kH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "envs.single_observation_space"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiulskLVONrO",
        "outputId": "8d208d09-721e-4ea9-e790-516d5c459da1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Box(-inf, inf, (17,), float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "runs = wandb_runs(cfg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "bY4z2rMkXM4v",
        "outputId": "acac8616-d9ef-4d92-e517-828a1a1c0848"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33majheshbasnet\u001b[0m (\u001b[33majheshbasnet-kpriet\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.24.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20260207_131435-50exe7jt</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg/runs/50exe7jt' target=\"_blank\">DDPG</a></strong> to <a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg' target=\"_blank\">https://wandb.ai/ajheshbasnet-kpriet/ddpg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ajheshbasnet-kpriet/ddpg/runs/50exe7jt' target=\"_blank\">https://wandb.ai/ajheshbasnet-kpriet/ddpg/runs/50exe7jt</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Heart & Core of the notebook: DDPG Algorithm's Training Loop**"
      ],
      "metadata": {
        "id": "CU_YjGWi3biG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for _ in tqdm(range(cfg.n_rollouts)):\n",
        "\n",
        "  states = envs.reset()[0]\n",
        "\n",
        "  statesT= torch.tensor(states, dtype=torch.float32, device = cfg.device)\n",
        "\n",
        "  training_rewards = torch.zeros((cfg.n_envs,), device = cfg.device)\n",
        "\n",
        "\n",
        "  for _ in range(cfg.max_steps):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      action = actornet(statesT).cpu()\n",
        "\n",
        "    action = np.array(action) + action_sigma * np.random.rand(cfg.n_envs, 6)\n",
        "\n",
        "    next_states, rewards, terminated, truncated, _ =  envs.step(action)\n",
        "\n",
        "    done = terminated | truncated\n",
        "\n",
        "    next_statesT = torch.tensor(next_states, dtype=torch.float32, device = cfg.device)\n",
        "\n",
        "    actionT = torch.tensor(action, dtype=torch.float32, device = cfg.device)\n",
        "\n",
        "    rewardsT = torch.tensor(rewards, dtype=torch.float32, device=cfg.device)\n",
        "\n",
        "    training_rewards += rewardsT\n",
        "\n",
        "    doneT = torch.tensor(done, dtype=torch.bool, device = cfg.device)\n",
        "\n",
        "    replay_buffer.append((statesT, actionT, rewardsT, next_statesT, doneT))\n",
        "\n",
        "    if (global_step + 1) % cfg.trainng_step == 0 and len(replay_buffer)>80_000:\n",
        "      # Sample batch\n",
        "      states_b, action_b, reward_b, next_states_b, dones_b = get_batches(replay_buffer, cfg.batch_size)\n",
        "\n",
        "      # Target Q\n",
        "      with torch.no_grad():\n",
        "        next_action = TargetActor(next_states_b)\n",
        "        target_next_q = TargetCritic(next_states_b, next_action)\n",
        "        target_q = reward_b + gamma * target_next_q * (1 - dones_b.float())\n",
        "\n",
        "      # Current critic Q\n",
        "      current_q = criticnet(states_b, action_b)\n",
        "\n",
        "      # Critic loss\n",
        "      critic_loss = torch.nn.functional.mse_loss(current_q, target_q)\n",
        "\n",
        "      # Actor loss (use current actor)\n",
        "      # Clone states_b to create an independent computational graph for actor update\n",
        "      states_b_actor = states_b.clone()\n",
        "      actor_actions = actornet(states_b_actor) # Renamed to avoid shadowing action_b from get_batches\n",
        "      actor_loss = -criticnet(states_b_actor, actor_actions).mean()\n",
        "\n",
        "      runs.log(\n",
        "          {\n",
        "              \"actor-loss\": actor_loss.item(),\n",
        "              \"critic-loss\": critic_loss.item()\n",
        "          }\n",
        "      )\n",
        "\n",
        "      # Optimize actor\n",
        "      actor_optimizer.zero_grad()\n",
        "      actor_loss.backward()\n",
        "\n",
        "      # Optimize critic\n",
        "      critic_optimizer.zero_grad()\n",
        "      critic_loss.backward()\n",
        "\n",
        "      critic_optimizer.step()\n",
        "      actor_optimizer.step()\n",
        "\n",
        "      # Soft update targets\n",
        "      for target_param, param in zip(TargetCritic.parameters(), criticnet.parameters()):\n",
        "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "      for target_param, param in zip(TargetActor.parameters(), actornet.parameters()):\n",
        "          target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
        "\n",
        "      if global_step%cfg.eval_steps==0 and global_step>0:\n",
        "\n",
        "        rec = True if global_step%cfg.record_video==0 else False\n",
        "        eval_reward, eval_steps = evaluation(actornet, rec)\n",
        "        runs.log(\n",
        "            {\n",
        "                \"eval-reward\": eval_reward,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    if all(done):\n",
        "      runs.log({\"training-reward\": training_rewards.mean().item()})\n",
        "\n",
        "    statesT = next_statesT\n",
        "    runs.log({\"global-steps\": global_step, \"memory\": len(replay_buffer)})\n",
        "    global_step += 1"
      ],
      "metadata": {
        "id": "AnYrCFL0XspN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "4d9287a7-9077-4d58-d59b-e202ce481da7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 500/100000 [1:39:32<478:39:06, 17.32s/it]/usr/local/lib/python3.12/dist-packages/moviepy/config_defaults.py:47: SyntaxWarning: invalid escape sequence '\\P'\n",
            "  IMAGEMAGICK_BINARY = r\"C:\\Program Files\\ImageMagick-6.8.8-Q16\\magick.exe\"\n",
            "  1%|          | 689/100000 [2:42:52<391:16:35, 14.18s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-391797660.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0;31m# Soft update targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtarget_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTargetCritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriticnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m           \u001b[0mtarget_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtarget_param\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtarget_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTargetActor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactornet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run the below cell to save the video from the latest Actor Network**"
      ],
      "metadata": {
        "id": "BL52dUql3pwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation(actornet, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aDI241Wi0nc",
        "outputId": "07767afd-298a-4ff1-fe37-57951f34052e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5154.715834142035, 1000.0)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}